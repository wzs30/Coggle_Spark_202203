{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spark基础教程\n",
    "\n",
    "Spark是一个快速和通用的大数据引擎，可以通俗的理解成一个分布式的大数据处理框架，允许用户将Spark部署在大量廉价的硬件之上，形成集群。Spark使用scala 实现，提供了 JAVA, Python，R等语言的调用接口。在本次学习我们将学习如何使用Spark清洗数据，并进行基础的特征工程操作，帮助大家掌握基础PySpark技能。\n",
    "\n",
    "学习资料：\n",
    "\n",
    "https://spark.apache.org/docs/latest/quick-start.html\n",
    "\n",
    "https://spark.apache.org/docs/latest/sql-programming-guide.html\n",
    "\n",
    "https://github.com/apache/spark/tree/4f25b3f712/examples/src/main/python\n",
    "\n",
    "https://sparkbyexamples.com/pyspark-tutorial/\n",
    "\n",
    "https://www.tutorialspoint.com/pyspark/index.htm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 任务1：PySpark数据处理\n",
    "\n",
    "- 步骤1：使用Python链接Spark环境\n",
    "- 步骤2：创建dateframe数据\n",
    "- 步骤3：用spark执行以下逻辑：找到数据行数、列数\n",
    "- 步骤4：用spark筛选class为1的样本\n",
    "- 步骤5：用spark筛选language >90 或 math> 90的样本"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 步骤1：使用Python链接Spark环境"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 添加此代码，进行spark初始化\n",
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 步骤2：创建dateframe数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+--------+----+-------+------+--------+\n",
      "|number|class|language|math|english|physic|chemical|\n",
      "+------+-----+--------+----+-------+------+--------+\n",
      "|   001|    1|     100|  87|     67|    83|      98|\n",
      "|   002|    2|      87|  81|     90|    83|      83|\n",
      "|   003|    3|      86|  91|     83|    89|      63|\n",
      "|   004|    2|      65|  87|     94|    73|      88|\n",
      "|   005|    1|      76|  62|     89|    81|      98|\n",
      "|   006|    3|      84|  82|     85|    73|      99|\n",
      "|   007|    3|      56|  76|     63|    72|      87|\n",
      "|   008|    1|      55|  62|     46|    78|      71|\n",
      "|   009|    2|      63|  72|     87|    98|      64|\n",
      "+------+-----+--------+----+-------+------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 导入相关库\n",
    "import pandas as pd\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName('pyspark') \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# 原始数据 \n",
    "test = spark.createDataFrame([('001','1',100,87,67,83,98), ('002','2',87,81,90,83,83), ('003','3',86,91,83,89,63),\n",
    "                                ('004','2',65,87,94,73,88), ('005','1',76,62,89,81,98), ('006','3',84,82,85,73,99),\n",
    "                                ('007','3',56,76,63,72,87), ('008','1',55,62,46,78,71), ('009','2',63,72,87,98,64)],\n",
    "                            ['number','class','language','math','english','physic','chemical'])\n",
    "test.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 步骤3：用spark执行以下逻辑：找到数据行数、列数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "行数:9\n",
      "列数:7\n"
     ]
    }
   ],
   "source": [
    "print(f'行数:{test.count()}\\n列数:{len(test.columns)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 步骤4：用spark筛选class为1的样本"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+--------+----+-------+------+--------+\n",
      "|number|class|language|math|english|physic|chemical|\n",
      "+------+-----+--------+----+-------+------+--------+\n",
      "|   001|    1|     100|  87|     67|    83|      98|\n",
      "|   005|    1|      76|  62|     89|    81|      98|\n",
      "|   008|    1|      55|  62|     46|    78|      71|\n",
      "+------+-----+--------+----+-------+------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test.filter(test['class'] == '1').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 步骤5：用spark筛选language >90 或 math> 90的样本"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+--------+----+-------+------+--------+\n",
      "|number|class|language|math|english|physic|chemical|\n",
      "+------+-----+--------+----+-------+------+--------+\n",
      "|   001|    1|     100|  87|     67|    83|      98|\n",
      "|   003|    3|      86|  91|     83|    89|      63|\n",
      "+------+-----+--------+----+-------+------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "f1 = test['language'] > 90\n",
    "f2 = test['math'] > 90\n",
    "test.filter(f1|f2).show()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "48de46c395bdbfc127f71df84d0b8cef7bb4c63b5f8ed81eab1950674a230645"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
